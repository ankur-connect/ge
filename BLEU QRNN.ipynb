{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bleu score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import random\n",
    "import re\n",
    "import collections\n",
    "import torch\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"/Users/carolineroper/Documents/School/Natural Language Processing/quasi-rnn-original/dev_target_seqs.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    \n",
    "    targets = []\n",
    "    \n",
    "    for i, line in enumerate(f):\n",
    "        \n",
    "        line = line.split('<JOIN>')\n",
    "        targets.append(line[0])\n",
    "        \n",
    "    \n",
    "with open(\"/Users/carolineroper/Documents/School/Natural Language Processing/quasi-rnn-original/decoded_original.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    \n",
    "    predictions = []\n",
    "    s2=[]\n",
    "    \n",
    "    for i, line in enumerate(f):\n",
    "        s1=(line.split('  '))\n",
    "        #print(s1)\n",
    "        for k, word in enumerate(s1):\n",
    "            s2.append(\" \".join([\"\".join(w.split(\" \")) for w in word.split(\"  \")]))\n",
    "        predictions.append(\" \".join(s2))\n",
    "        s2=[]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"/Users/carolineroper/Documents/School/Natural Language Processing/quasi-rnn-original/decoded_batched.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    \n",
    "    predictions2 = []\n",
    "    s2=[]\n",
    "    \n",
    "    for i, line in enumerate(f):\n",
    "        s1=(line.split('  '))\n",
    "        #print(s1)\n",
    "        for k, word in enumerate(s1):\n",
    "            s2.append(\" \".join([\"\".join(w.split(\" \")) for w in word.split(\"  \")]))\n",
    "        predictions2.append(\" \".join(s2))\n",
    "        s2=[]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hypothesis =  predictions2[2]\n",
    "reference = targets[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Simply, the knowledge that Jaguar schaman still recovered or the milky was always the main of the milkyard of the oil in the milk of the oil in the myth of the oil in the million the myths of oil in the million the myth of the propology of the minutes of the profound our own internal possibilities t\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Simply the knowledge that Jaguar shamans always always still so far for the milk or meaningful the meaningful of the innovation of the innovation of the innovation of the innovation of the innovation of the innovation of the innovation of the innovation of the innovation of anthropology that the wor\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There's some magical amount. I don't know what it is.\n",
      " There's a magic person. I don't know what it is.\n",
      " There is a magical lunch. I don't know what it is.\n",
      "\n",
      "And sixteen milliseconds , also a very exciting phenomenon .\n",
      " And six billiseconds are also -- a whole little phenomenon.\n",
      " And six milliseconds -- also a very strong phenomenon.\n",
      "\n",
      "Perhaps you've heard of that already , if you have any interest in that , in connection with the Australian aboriginals .\n",
      " This maybe you know, maybe if you an interest in this a little bit interested in the way that you see that a little interested in the same thing about.\n",
      " This is a lot of mind that you might be able to interest in the way that you can interest in the middle of the extral authority.\n",
      "\n",
      "Now, the fascinating things are that the beta-carbolines found within that liana are MAO inhibitors of the precise sort necessary to potentiate the tryptamine. So you ask yourself a question.\n",
      " Now the fascinating is that the betaca betaca in looking in lianity in lianish, MAO-itors of exactly the way that they are necessary to potential to potential the trying to potential the tryptions. So you see them asking.\n",
      " Now the fascinating is that the contention is that the carbon online, which is a liarship of the liars are contagious, MAO is the same thing that is necessary to potential. So it's a self-esteem.\n",
      "\n",
      "It doesn't make any difference because the only thing that ought to limit the performance of a system like this one is the number of pixels on your screen at any given moment. It's also very flexible architecture.\n",
      " It doesn't make any difference, because the only one system is like this in this one system like this is a very single system like this one, the number of pixels in the screen that is a very lexible architecture.\n",
      " It doesn't make a difference because that only what the system can be like this is a system like this incredibly can be able to do is any very flexible architecture.\n",
      "\n",
      "So what are archaic models ?\n",
      " What are the ones actually archaic models?\n",
      " What are the architecture now is architecture?\n",
      "\n",
      "Of course this lends itself to a smart grid .\n",
      " Now, of course, then you offer smart grid.\n",
      " Of course, smart grid of the smart grid.\n",
      "\n",
      "So I don't have to plan it out in advance, but I can improvise, making it longer or shorter as I go.\n",
      " I don't have to invest in the bird that I can't plan to be plan improvising in the billboard; they do so during or short shortly.\n",
      " I don't have to plan them in the part of the plane, but improvising improvising or strong or strength.\n",
      "\n",
      "And you say, \"Doc, what should I do?\"\n",
      " And you say, \"Doc, what about this?\"\n",
      " And you say, \"Doctor, what should I do?\"\n",
      "\n",
      "Now, if you begin to look at the idea that these cultures could create different realities, you could begin to understand some of their extraordinary discoveries. Take this plant here.\n",
      " Now, if you start begins to look at the idea that these cultures different realities, you can understand some of their extraordinary discoveries, you can understand some of their extraordinary discoveries. CBs an extraordinary discoveries.\n",
      " Well, if you start looking at the idea that these cultures can create different realities, you can understand some of their outsiders can understand some of their outsiders there.\n",
      "\n",
      "Yes, I'm afraid of all those things.\n",
      " Yes, I fear of all those things.\n",
      " Yes, I was fear all of these things that way.\n",
      "\n",
      "Yes, so to speak .\n",
      " Yes, sort of looking for sorts.\n",
      " Yes to the same thing.\n",
      "\n",
      "Because he led you down a path he's not on himself .\n",
      " Because he didn't respond to a bike should have led to stop at the finished.\n",
      " Because he was going to get your stuff to get on the stock of itself and not stopping yourself on the stock of it.\n",
      "\n",
      "That here is Biocurious , the hackerspace I mentioned just now , this yes , basically a kind of adult education centre for for molecular biology .\n",
      " Here in the picture of the picture of the lab and in the bottom leadership -- and so it's so essentially a projection of so much lab that what I wanted to do with that and the unit does interesting things that I want to project that and the unit is pretty so interesting things that I want to put a p\n",
      " And here in the picture you see is the lab -- in leaders -- so in leaders -- so it's a probably garage with all the lab school completely success that the unique and make a group of the university that was a group of the universe and also interesting things that want to do what was what was what was\n",
      "\n",
      "We need to go far, quickly.\n",
      " We have to come fast, and that's fast.\"\n",
      " We have to come far, and that's when you get to the point.\n",
      "\n",
      "According to which logic do we disseminate this deception , this self-deception , this willingness to present a reality that's different from the reality we know is valid in our unconscious minds ?\n",
      " I want to talk to you about this in my institution.\n",
      " I want to talk to you to the problem with what we found in my institute.\n",
      "\n",
      "I'd like to reintroduce you to a particular aspect of curiosity .\n",
      " I want to be able to prevent to a whole aspect of newing curiosity.\n",
      " I want to help you to say that way to say that way to get the state of curiosity.\n",
      "\n",
      "And I would imagine that a lot of you have too.\n",
      " And I look at that many of you did that.\n",
      " And I was approaching that many of you have done this to you.\n",
      "\n",
      "This old man's grandfather refused to go.\n",
      " The grandfather of this old man's resident man.\n",
      " The great father that old men was fully further.\n",
      "\n",
      "And you wouldn't be able to save energy .\n",
      " You can't spend any energy.\n",
      " You can't store energy.\n",
      "\n",
      "This is the map of a small organism, Mycoplasma genitalium, that has the smallest genome for a species that can self-replicate in the laboratory, and we've been trying to just see if we can come up with an even smaller genome.\n",
      " This is the card of a little organism, Mycoplasma mycoplasma doing that smallest genome and have a species of a species of a species of a species of the species of a species of a species of the lab.\n",
      " This is the map of a little organism, mycoplasma gime who can replicate the smallest genome of a species of a species of the lab and we try to try to try to try to get whether we can try to an enough genome.\n",
      "\n",
      "You've got to admit that's a lot of choice.\n",
      " You have to admit that that they have to be a big choice.\n",
      " You have to add that this is a big shot of the time.\n",
      "\n",
      "That means we first project what we see before we actually see it , then we bring that to the back into our seeing machine , and then we say, okay ,\n",
      " This is what we project our seeing seeing things before we see it -- okay after that see in our setting up to say to say, OK, okay, are okay -- okay -- okay -- okay -- okay -- okay --\n",
      " This is what we see is the first one of the statement of the seats before we see it in our seeing some behind our seeing seeing in our seeing seeing some of the back in our seeing seeing the seeing seeing there.\n",
      "\n",
      "Here Here it's more likely to turn into my glasses .\n",
      " There's a more than more to my brilled the brilliance.\n",
      " There we go to my brilliant money.\n",
      "\n",
      "There's the OPEC , a a bunch of amateurs .\n",
      " There's the opec of a bunch of waiting for the bunch of waiting.\n",
      " There's the opec of the way that we have a bunch of organizations.\n",
      "\n",
      "I'm not sure if I have time to show you any other environments.\n",
      " I'm not really knowing that I have time you to show other environments.\n",
      " I don't know exactly whether I have time to show you other environments to show you other environments.\n",
      "\n",
      "But it's also a code , and you can program that and so you can also hack into it , that's it , and I thought think it's incredibly fascinating , and I just wanted to really delve into that .\n",
      " But it's also a code -- and you can also talk about that you can also have a programming that you can also have it to the way that I think that I think about it and that way that I think about the way I think about the minimulation and that I just wanted to be a lot of deeper with a deep incredibly \n",
      " But it's also a code -- and you can also programmed it and come and come and come and come and find it into incredibly fascinating and there wanted to fast incredibly fascinating with one on the stage.\n",
      "\n",
      "Well, how do we boot up a chromosome? How do we activate this?\n",
      " Now how do we start a chromosome? How do we activate?\n",
      " Well, what do we start to do with this? How are we activated?\n",
      "\n",
      "Yes , I'm very happy to be here .\n",
      " Yes, I was very sort of like this, and I was a little bit about this.\n",
      " Yes, I want to get to the point of the way to get to you and for you.\n",
      "\n",
      "There is not one single tree that is carbon neutral .\n",
      " No ball is coaloneline.\n",
      " No tree is called the car than the way that was a bit of a stranger.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "randoms = random.sample(range(0,len(targets)), 30)\n",
    "\n",
    "for i in randoms:\n",
    "    print (targets[i], predictions[i], predictions2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BLEUscore = nltk.translate.bleu_score.sentence_bleu([hypothesis.split()], reference.split(), emulate_multibleu = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLEUscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/anaconda/lib/python3.6/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/anaconda/lib/python3.6/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "bleu=[]\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    bleu.append(nltk.translate.bleu_score.sentence_bleu([targets[i].split()], predictions[i].split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33989591102938616\n"
     ]
    }
   ],
   "source": [
    "average_bleu=sum(bleu) / float(len(bleu))\n",
    "print(average_bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/anaconda/lib/python3.6/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/anaconda/lib/python3.6/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "bleu=[]\n",
    "\n",
    "for i in range(len(predictions2)):\n",
    "    bleu.append(nltk.translate.bleu_score.sentence_bleu([targets[i].split()], predictions2[i].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33591988904846415\n"
     ]
    }
   ],
   "source": [
    "average_bleu=sum(bleu) / float(len(bleu))\n",
    "print(average_bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "BLEUscore = \\\n",
    "nltk.translate.bleu_score.corpus_bleu([t.split() for t in targets],\\\n",
    "                                      [p.split() for p in predictions],\\\n",
    "                                     auto_reweigh = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4134420551529745"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLEUscore #corpus BLEU is higher than avg sentence BLEU, .41."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "BLEUscore = \\\n",
    "nltk.translate.bleu_score.corpus_bleu([t.split() for t in targets],\\\n",
    "                                      [p.split() for p in predictions2],\\\n",
    "                                     auto_reweigh = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39897699154308114"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLEUscore #corpus BLEU score of final is a little bit worse than the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "'''\n",
    "According to this paper: http://www.aclweb.org/anthology/I/I05/I05-2014.pdf\n",
    "A Bleu_4 Score in Word Level corresponds to Bleu_18 Score in Character Level.\n",
    "Hence, in this project, we are using a Character Level Bleus of values: 5, 10, 15, 20.\n",
    "Ref: \n",
    "https://github.com/vikasnar/Bleu\n",
    "https://github.com/MaximumEntropy/Seq2Seq-PyTorch/blob/master/evaluate.py\n",
    "'''\n",
    "\n",
    "import os\n",
    "import math\n",
    "import operator\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "def count_ngram(candidate, references, n):\n",
    "    \"\"\"\n",
    "    Character Level n-gram counter\n",
    "    \n",
    "    @return \n",
    "        precision and brevity penalty\n",
    "    \"\"\"\n",
    "    clipped_count = 0\n",
    "    count = 0\n",
    "    r = 0\n",
    "    c = 0\n",
    "    \n",
    "    for s_i in range(len(candidate)):\n",
    "        \n",
    "        # Calculate precision for each sentence\n",
    "        ref_counts = []\n",
    "        ref_lengths = []\n",
    "        \n",
    "        # Build dictionary of ngram counts\n",
    "        for reference in references:\n",
    "            ref_sentence = reference[s_i]\n",
    "            ngram_d = {}\n",
    "            chars = [i for i in ref_sentence.strip()]\n",
    "            ref_lengths.append(len(chars))\n",
    "            limits = len(chars) - n + 1\n",
    "            \n",
    "            # loop through the sentance consider the ngram length\n",
    "            for i in range(limits):\n",
    "                ngram = ' '.join(chars[i:i+n])\n",
    "                if ngram in ngram_d.keys():\n",
    "                    ngram_d[ngram] += 1\n",
    "                else:\n",
    "                    ngram_d[ngram] = 1\n",
    "            ref_counts.append(ngram_d)\n",
    "            \n",
    "        # candidate\n",
    "        cand_sentence = candidate[s_i]\n",
    "        cand_dict = {}\n",
    "        chars = [i for i in cand_sentence.strip()]\n",
    "        limits = len(chars) - n + 1\n",
    "        for i in range(0, limits):\n",
    "            ngram = ' '.join(chars[i:i + n])\n",
    "            if ngram in cand_dict:\n",
    "                cand_dict[ngram] += 1\n",
    "            else:\n",
    "                cand_dict[ngram] = 1\n",
    "                \n",
    "        clipped_count += clip_count(cand_dict, ref_counts)\n",
    "        count += limits\n",
    "        r += best_length_match(ref_lengths, len(chars))\n",
    "        c += len(chars)\n",
    "        \n",
    "    if clipped_count == 0:\n",
    "        pr = 0\n",
    "    else:\n",
    "        pr = float(clipped_count) / count\n",
    "        \n",
    "    bp = brevity_penalty(c, r)\n",
    "    \n",
    "    return pr, bp\n",
    "\n",
    "\n",
    "def clip_count(cand_d, ref_ds):\n",
    "    \"\"\"\n",
    "    Count the clip count for each ngram considering all references\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for m in cand_d.keys():\n",
    "        m_w = cand_d[m]\n",
    "        m_max = 0\n",
    "        for ref in ref_ds:\n",
    "            if m in ref:\n",
    "                m_max = max(m_max, ref[m])\n",
    "        m_w = min(m_w, m_max)\n",
    "        count += m_w\n",
    "    return count\n",
    "\n",
    "\n",
    "def best_length_match(ref_l, cand_l):\n",
    "    \"\"\"\n",
    "    Find the closest length of reference to that of candidate\n",
    "    \"\"\"\n",
    "    least_diff = abs(cand_l-ref_l[0])\n",
    "    best = ref_l[0]\n",
    "    for ref in ref_l:\n",
    "        if abs(cand_l-ref) < least_diff:\n",
    "            least_diff = abs(cand_l-ref)\n",
    "            best = ref\n",
    "    return best\n",
    "\n",
    "\n",
    "def brevity_penalty(c, r):\n",
    "    if c > r:\n",
    "        bp = 1\n",
    "    else:\n",
    "        bp = math.exp(1-(float(r)/c))\n",
    "    return bp\n",
    "\n",
    "\n",
    "def geometric_mean(precisions):\n",
    "    return (reduce(operator.mul, precisions)) ** (1.0 / len(precisions))\n",
    "\n",
    "\n",
    "def BLEU(candidate, references):\n",
    "    precisions = []\n",
    "    for i in range(5, 21, 5):\n",
    "        pr, bp = count_ngram(candidate, references, i+1)\n",
    "        precisions.append(pr)\n",
    "    bleu = geometric_mean(precisions) * bp\n",
    "    return bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bleus = []\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    bleus.append(BLEU([predictions[i]], [[targets[i]]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
