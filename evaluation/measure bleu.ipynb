{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bleu score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bilals01/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "run -i bleu.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "import re\n",
    "import random\n",
    "import collections\n",
    "import torch\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "#%%\n",
    "    \n",
    "with open(\"/Users/bilals01/Documents/NLP/project/quasi-rnn-run-12-09/targets.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    \n",
    "    targets = []\n",
    "    \n",
    "    for i, line in enumerate(f):\n",
    "        \n",
    "        line = line.split('<JOIN>')\n",
    "        targets.append(line[0])\n",
    "        \n",
    "        \n",
    "with open(\"/Users/bilals01/Documents/NLP/project/quasi-rnn-run-12-09/dev_source_seqs.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    \n",
    "    source = []\n",
    "    \n",
    "    for i, line in enumerate(f):\n",
    "        \n",
    "        line = line.split('<JOIN>')\n",
    "        source.append(line[0])\n",
    "        \n",
    "    \n",
    "with open(\"/Users/bilals01/Documents/NLP/project/quasi-rnn-run-12-09/predictions.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    \n",
    "    predictions = []\n",
    "    s2=[]\n",
    "    \n",
    "    for i, line in enumerate(f):\n",
    "        s1=(line.split('  '))\n",
    "        #print(s1)\n",
    "        for k, word in enumerate(s1):\n",
    "            s2.append(\" \".join([\"\".join(w.split(\" \")) for w in word.split(\"  \")]))\n",
    "        predictions.append(\" \".join(s2))\n",
    "        s2=[]\n",
    "        \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.17\n"
     ]
    }
   ],
   "source": [
    "#bleu score\n",
    "b=moses_multi_bleu(predictions, targets, lowercase=False)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid of /n \n",
    "source_u=[]\n",
    "for i, s in enumerate(source):\n",
    "    source_u.append(s.strip())\n",
    "\n",
    "target_u=[]\n",
    "for i, t in enumerate(targets):\n",
    "    target_u.append(t.strip())\n",
    "    \n",
    "pred_u=[]\n",
    "for i, p in enumerate(predictions):\n",
    "    pred_u.append(p.strip())   \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/bilals01/Documents/NLP/project/quasi-rnn-run-12-09/compounds.txt\", \"r\", encoding=\"utf8\") as comp:\n",
    "    compound_words = []\n",
    "    \n",
    "    for i,line in enumerate(comp):\n",
    "        \n",
    "        compound_words.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.62\n"
     ]
    }
   ],
   "source": [
    "#experiment-1: find the sentences where the compound words occurs and  \n",
    "#find the  bleu score for those\n",
    "pred_comp=[]\n",
    "target_comp=[]\n",
    "\n",
    "for i in range(len(pred_u)):\n",
    "    for w in source_u[i].split():\n",
    "        if w in compound_words:\n",
    "            pred_comp.append(pred_u[i])\n",
    "            target_comp.append(target_u[i])\n",
    "            break\n",
    "                  \n",
    "#print(pred_comp[5]) \n",
    "#print(target_comp[5]) \n",
    "blue_comp=moses_multi_bleu(pred_comp, target_comp, lowercase=False)\n",
    "\n",
    "print(blue_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.71590909090909\n"
     ]
    }
   ],
   "source": [
    "#experiment-2: find the sentences where the compound words occurs and \n",
    "#count the number of words in each sentence.\n",
    "target_length=[]\n",
    "\n",
    "for i in range(len(pred_u)):\n",
    "    for w in source_u[i].split():\n",
    "        if w in compound_words:\n",
    "            target_length.append(len(pred_u[i].split()))\n",
    "            break\n",
    "            \n",
    "print(sum(target_length) / float(len(target_length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
